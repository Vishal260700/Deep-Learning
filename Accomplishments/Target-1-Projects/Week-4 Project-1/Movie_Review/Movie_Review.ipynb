{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_Review.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "6Ks21vxuLB_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLxP2yHSLOzj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test) = imdb.load_data(num_words = 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-LRT_QaLigv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y4cBvSgkLk92",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decode_review(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SfB7dCcWNI4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train , value = word_index[\"<PAD>\"] , padding = \"post\" , maxlen = 256)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test , value = word_index[\"<PAD>\"] , padding = \"post\" , maxlen = 256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KZJK8Y0bNkkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "7bf326cb-47cf-4657-e7cc-b53a4d147cb2"
      },
      "cell_type": "code",
      "source": [
        "vocSize = 10000\n",
        "\n",
        "# model architecture\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocSize , 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16 , activation = tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1 , activation = tf.nn.sigmoid))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7KunLJIOTni",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"binary_crossentropy\" , optimizer = tf.train.AdamOptimizer() , metrics = [\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWVhwnICO7ya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1378
        },
        "outputId": "01ac0953-c073-4f3b-9ae1-4e7693d25368"
      },
      "cell_type": "code",
      "source": [
        "x_val = x_train[:10000]\n",
        "part_x = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "part_y = y_train[10000:]\n",
        "\n",
        "history = model.fit(part_x , part_y , epochs = 40 , batch_size = 512 , validation_data = (x_val , y_val) , verbose = 1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 85us/step - loss: 0.6919 - acc: 0.5799 - val_loss: 0.6902 - val_acc: 0.7055\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 1s 67us/step - loss: 0.6868 - acc: 0.7423 - val_loss: 0.6832 - val_acc: 0.7541\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 1s 66us/step - loss: 0.6755 - acc: 0.7695 - val_loss: 0.6685 - val_acc: 0.7623\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 1s 67us/step - loss: 0.6540 - acc: 0.7749 - val_loss: 0.6438 - val_acc: 0.7712\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 1s 66us/step - loss: 0.6203 - acc: 0.7974 - val_loss: 0.6069 - val_acc: 0.7896\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 1s 67us/step - loss: 0.5765 - acc: 0.8131 - val_loss: 0.5644 - val_acc: 0.8009\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 1s 67us/step - loss: 0.5275 - acc: 0.8310 - val_loss: 0.5196 - val_acc: 0.8208\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 1s 66us/step - loss: 0.4786 - acc: 0.8473 - val_loss: 0.4771 - val_acc: 0.8336\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 1s 64us/step - loss: 0.4340 - acc: 0.8593 - val_loss: 0.4399 - val_acc: 0.8435\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.3947 - acc: 0.8738 - val_loss: 0.4091 - val_acc: 0.8512\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.3621 - acc: 0.8820 - val_loss: 0.3863 - val_acc: 0.8556\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 1s 64us/step - loss: 0.3351 - acc: 0.8881 - val_loss: 0.3642 - val_acc: 0.8627\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 1s 64us/step - loss: 0.3110 - acc: 0.8950 - val_loss: 0.3489 - val_acc: 0.8681\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.2912 - acc: 0.9009 - val_loss: 0.3354 - val_acc: 0.8713\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.2741 - acc: 0.9057 - val_loss: 0.3250 - val_acc: 0.8738\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.2594 - acc: 0.9089 - val_loss: 0.3165 - val_acc: 0.8766\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.2453 - acc: 0.9153 - val_loss: 0.3095 - val_acc: 0.8778\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.2331 - acc: 0.9203 - val_loss: 0.3037 - val_acc: 0.8810\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.2217 - acc: 0.9244 - val_loss: 0.2990 - val_acc: 0.8816\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.2117 - acc: 0.9266 - val_loss: 0.2952 - val_acc: 0.8822\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.2019 - acc: 0.9306 - val_loss: 0.2920 - val_acc: 0.8834\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1930 - acc: 0.9349 - val_loss: 0.2900 - val_acc: 0.8838\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1848 - acc: 0.9378 - val_loss: 0.2884 - val_acc: 0.8837\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.1766 - acc: 0.9427 - val_loss: 0.2865 - val_acc: 0.8835\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.1695 - acc: 0.9459 - val_loss: 0.2856 - val_acc: 0.8846\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1623 - acc: 0.9480 - val_loss: 0.2854 - val_acc: 0.8846\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1563 - acc: 0.9517 - val_loss: 0.2857 - val_acc: 0.8857\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 1s 64us/step - loss: 0.1500 - acc: 0.9535 - val_loss: 0.2853 - val_acc: 0.8863\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1441 - acc: 0.9553 - val_loss: 0.2858 - val_acc: 0.8860\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.1390 - acc: 0.9571 - val_loss: 0.2869 - val_acc: 0.8861\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.1330 - acc: 0.9605 - val_loss: 0.2881 - val_acc: 0.8865\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1283 - acc: 0.9626 - val_loss: 0.2898 - val_acc: 0.8863\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1229 - acc: 0.9651 - val_loss: 0.2915 - val_acc: 0.8855\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1184 - acc: 0.9666 - val_loss: 0.2937 - val_acc: 0.8853\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.1143 - acc: 0.9677 - val_loss: 0.2954 - val_acc: 0.8855\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1094 - acc: 0.9694 - val_loss: 0.2983 - val_acc: 0.8848\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 1s 62us/step - loss: 0.1055 - acc: 0.9707 - val_loss: 0.3011 - val_acc: 0.8845\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.1021 - acc: 0.9717 - val_loss: 0.3036 - val_acc: 0.8835\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.0977 - acc: 0.9732 - val_loss: 0.3061 - val_acc: 0.8836\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 1s 63us/step - loss: 0.0940 - acc: 0.9753 - val_loss: 0.3094 - val_acc: 0.8828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QP4neKiOQwos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ac7eb8fb-e263-4d07-ce30-3a28ce7be225"
      },
      "cell_type": "code",
      "source": [
        "hit = model.evaluate(x_test , y_test)\n",
        "\n",
        "print(hit[0]) # loss\n",
        "print(hit[1]) # accuracy"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 39us/step\n",
            "0.3298557037162781\n",
            "0.87252\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}